{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSESSMENT\n",
    "    Data: 1. articles.csv - contains 1000 articles that cuta cross      various fields\n",
    "    Data: 2. google-phd-program.txt - a short article on google's proposed new PhD program.\n",
    "    Data: 3. comment.txt - A comment to google article.\n",
    "    \n",
    "    Data: 4. oliver-twist-0-9.txt - Chapters 1-9 of the charles dickens popular book Oliver Twist\n",
    "    \n",
    "    \n",
    "    Instruction: Read the command in each cell and write code to give the same output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standrad libraries to injest the CSV file and read in the CSV file\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What does it mean to be successful? Perhaps, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Much has been made of Africa&amp;rsquo;s unfavorab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A few days after a Damaris Wambui Kamau and he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\\n\\n\\n\\nJust a few hours after their release o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>IPOA is investigating the murder of four peopl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           articles\n",
       "0   1  What does it mean to be successful? Perhaps, o...\n",
       "1   2  Much has been made of Africa&rsquo;s unfavorab...\n",
       "2   3  A few days after a Damaris Wambui Kamau and he...\n",
       "3   4  \\n\\n\\n\\nJust a few hours after their release o...\n",
       "4   5  IPOA is investigating the murder of four peopl..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the email addresses contained in entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# import standard package\n",
    "import re \n",
    "\n",
    "# Enter your regex pattern here. This may take several tries!\n",
    "\n",
    "pattern = r'\\w+@\\w+.\\w{3}'\n",
    "\n",
    "re.findall(pattern, page_two_text)\n",
    "\n",
    "\n",
    "#print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to perform standard imports\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an article object from the 'google-phd-program.txt' file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many sentences are conatined in the file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instead of receiving a boring paper diploma at the end of their PhDs, Google PhD graduates receive a priceless note handwritten by Jeff Dean on a napkin that says, “You have a PhD now.\n"
     ]
    }
   ],
   "source": [
    "# Print out the FOURTEENTH sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instead         ADV   advmod     instead        \n",
      "of              ADP   prep       of             \n",
      "receiving       VERB  pcomp      receive        \n",
      "a               DET   det        a              \n",
      "boring          ADJ   amod       boring         \n",
      "paper           NOUN  compound   paper          \n",
      "diploma         NOUN  dobj       diploma        \n",
      "at              ADP   prep       at             \n",
      "the             DET   det        the            \n",
      "end             NOUN  pobj       end            \n",
      "of              ADP   prep       of             \n",
      "their           ADJ   poss       -PRON-         \n",
      "PhDs            PROPN pobj       phds           \n",
      ",               PUNCT punct      ,              \n",
      "Google          PROPN compound   google         \n",
      "PhD             NOUN  compound   phd            \n",
      "graduates       VERB  nsubj      graduate       \n",
      "receive         VERB  ROOT       receive        \n",
      "a               DET   det        a              \n",
      "priceless       ADJ   amod       priceless      \n",
      "note            NOUN  dobj       note           \n",
      "handwritten     ADJ   acl        handwritten    \n",
      "by              ADP   agent      by             \n",
      "Jeff            PROPN compound   jeff           \n",
      "Dean            PROPN pobj       dean           \n",
      "on              ADP   prep       on             \n",
      "a               DET   det        a              \n",
      "napkin          NOUN  pobj       napkin         \n",
      "that            ADJ   nsubj      that           \n",
      "says            VERB  relcl      say            \n",
      ",               PUNCT punct      ,              \n",
      "“               PUNCT punct      \"              \n",
      "You             PRON  nsubj      -PRON-         \n",
      "have            VERB  ccomp      have           \n",
      "a               DET   det        a              \n",
      "PhD             NOUN  dobj       phd            \n",
      "now             ADV   advmod     now            \n",
      ".               PUNCT punct      .              \n"
     ]
    }
   ],
   "source": [
    "# For each token in the sentence above, print its text, POS tag,\n",
    "# dep tag and lemma. \n",
    "#Have values line up in columns like in the print output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Brain    PERSON  People, including fictional\n",
      "DeepMind        GPE     Countries, cities, states\n",
      "FAIR            ORG     Companies, agencies, institutions, etc.\n",
      "Stanford        ORG     Companies, agencies, institutions, etc.\n",
      "Berkeley        GPE     Countries, cities, states\n",
      "MIT             ORG     Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "# Extract entites in the SECOND sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a matcher called 'AI' that finds all occurrences\n",
    "# of the phrase \"Artificial Intelligence\" and word 'AI' in the article\n",
    "\n",
    "# First Run this standard import and call\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the patterns and add it to matcher:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5530044837203964789, 12, 13), (5530044837203964789, 47, 49), (5530044837203964789, 138, 139), (5530044837203964789, 155, 157), (5530044837203964789, 285, 286), (5530044837203964789, 408, 409), (5530044837203964789, 421, 422), (5530044837203964789, 458, 459)]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of matches called \"found_matches\" and print the list:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a FUNCTION that takes in a index and prints the sentence\n",
    "#in which the match at that index is found\n",
    "\n",
    "def print_match_sent(index):\n",
    "    \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It’s extremely difficult to find people with talent in Machine Learning and Artificial Intelligence these days, and it pained us to see so many of our amazing interns decline our return offers to go back to school for PhDs.\n"
     ]
    }
   ],
   "source": [
    "# print the sentence where the FOURTH match is \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the meantime, Google is already planning for the next way to find top AI talent.\n"
     ]
    }
   ],
   "source": [
    "# print the sentence where the last match is \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL to perform standard imports:\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83. ADJ  :48\n",
      "84. ADP  :56\n",
      "85. ADV  :22\n",
      "88. CCONJ:11\n",
      "89. DET  :30\n",
      "90. INTJ :1\n",
      "91. NOUN :116\n",
      "92. NUM  :3\n",
      "93. PART :15\n",
      "94. PRON :10\n",
      "95. PROPN:37\n",
      "96. PUNCT:62\n",
      "99. VERB :71\n",
      "102. SPACE:6\n"
     ]
    }
   ],
   "source": [
    "# Provide a frequency list of POS tags from the entire article\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/488 = 23.77%\n"
     ]
    }
   ],
   "source": [
    "# What percentage of tokens are nouns?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">In a move that is completely unsurprising to many, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "’s \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    AI\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " research division has announced that they are issuing \n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    PhD\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       " degrees to select employees.\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    \n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "Industry research organizations like \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Google Brain\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    DeepMind\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    FAIR\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " are well known as heavy hitters in the artificial intelligence research community, publishing as many papers (if not more) as academic institutions like \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Stanford\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Berkeley\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    MIT\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". Many top professors from academia have migrated over to industry research labs as well, sacrificing the security of academic tenure for fat stacks of money. Although \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " has previously experimented with research residencies, this is the \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    first\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " time that they have issued postgraduate degrees.\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    \n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "According to a representative, the tech giant decided to issue \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    PhDs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in order to attract scarce \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    AI\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " talent. “It’s extremely difficult to find people with talent in \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Machine Learning and Artificial Intelligence\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    these days\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", and it pained us to see so many of our amazing interns decline our return offers to go back to school for \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    PhDs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". With the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " PhD program, we can continue to get the best talent while supporting our student-employees with world class resources and technology.”\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    \n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "For graduate students, the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " PhD program is a sweet deal. There is already a well-known pipeline where top graduate students do their \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    PhDs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " at a university, intern at industry research groups during \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the summer\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", and then sign on full time after graduation with the promise of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    million-dollar\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " compensation packages and the freedom to set their own research agendas.\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    \n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "However, aspiring \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    AI\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " researchers must still struggle through the difficulties of academia: \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    four to six years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " of low pay, begging for funding, and advisors who can be sadistic, micromanaging, or absent. In contrast, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " offers researchers massive computational resources and motivates their \n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    PhD\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       " advisors with a potent combination of vegan snacks, kombucha, and equity refreshers. Instead of receiving a boring paper diploma at the end of their \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    PhDs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " PhD graduates receive a priceless note handwritten by \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Jeff Dean\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " on a napkin that says, “You have a \n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    PhD\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       " now.”\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    \n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "Other tech companies are scrambling to build their own research groups so they are not left behind in the “AI revolution.” Halting Problem reached out to a representative from \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Salesforce AI Research\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " who said, “What? \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is doing it? Well, guess we are too.”\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    \n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "In the meantime, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is already planning for the next way to find top \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    AI\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " talent. According to a knowledgeable source, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is in talks with \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Khan Academy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " to create a “machine learning kindergarten” program that teaches children \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Tensorflow\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the named entity visualization for the entire article\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL : Which named entity do you think is not well tagged\n",
    "\n",
    "# Answer here and why:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform VADER Sentiment Analysis on the Comment file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ikezogwo/anaconda3/envs/nlp_course/lib/python3.7/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "# Import SentimentIntensityAnalyzer and create an sid object\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "# kindly ignore the warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using 'open' read in the comment.txt file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.022, 'neu': 0.809, 'pos': 0.17, 'compound': 0.9186}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain the sid scores for the comment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write fucntion to take in a comment and returns whether it was \n",
    "# \"Positive\", \"Negative\" or \"Neutral\"\n",
    "\n",
    "def comment_sentiment(comment):\n",
    "    \n",
    "    #return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncomment = 'I think the math works out well for google as they get\\n           to have great talent working for them, but I'm not sure\\n           if its gonna be a fufilling experience for the grad \\n           studentes as there are certain systems built around \\n           traditional PhD programs that make it work so well,\\n           so much so that it attracts these same great talent'\\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a comment of the article (AFTER READING IT please) as one continuous string or (multiple sentences are ok)\n",
    "comment = 'PUT TEXT IN HERE'\n",
    "\n",
    "# As an example here is my own comment, please do not use mine.\n",
    "'''\n",
    "comment = 'I think the math works out well for google as they get\n",
    "           to have great talent working for them, but I\\'m not sure\n",
    "           if its gonna be a fufilling experience for the grad \n",
    "           studentes as there are certain systems built around \n",
    "           traditional PhD programs that make it work so well,\n",
    "           so much so that it attracts these same great talent'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your function on your comment above:\n",
    "comment_sentiment(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling with LDA and NMF\n",
    "First we'd look at LDA then NMF and at the end see how both pan out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for LDA\n",
    "Task: Use Count Vectorization to create a vectorized document sparse matrix. Use a max_df=0.9 and min_df=2 parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages i.e Countvectorizer, LDA\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1001x10339 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 109044 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the CV object, Fit and transform the countvectorizer \n",
    "# on the articles using the params giving above\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=10, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit LDA object to the sparse matrix fron the count vectorizer\n",
    "# Extracting 10 TOPICS with a RANDOM STATE of 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 15 WORDS FOR TOPIC #0\n",
      "['nigerian', 'police', 'south', 'statement', 'federal', 'according', 'states', 'national', 'security', 'buhari', 'people', 'nigeria', 'state', 'country', 'government', 'rsquo', 'president', 'rdquo', 'said', 'ldquo']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #1\n",
      "['general', 'rsquo', 'capital', 'market', 'business', 'programme', 'new', '2019', 'sec', 'rdquo', 'nigerian', 'nigeria', 'african', 'development', 'commission', 'company', '000', 'ldquo', 'africa', 'said']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #2\n",
      "['officers', '000', 'year', 'air', 'airlines', 'million', 'new', 'according', 'army', 'police', 'oil', 'project', 'government', 'state', 'nigeria', 'nigerian', 'rdquo', 'rsquo', 'ldquo', 'said']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #3\n",
      "['year', 'respondent', 'server', 'candidate', 'president', 'rdquo', 'apc', 'party', 'national', 'plastic', 'atiku', 'results', 'said', 'buhari', 'inec', 'rsquo', 'pdp', 'election', 'ldquo', 'presidential']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #4\n",
      "['energy', 'increase', 'africa', 'government', 'new', 'tax', 'market', 'agency', 'development', 'state', 'nnpc', 'national', 'million', 'according', 'gas', 'nigeria', 'rdquo', 'rsquo', 'ldquo', 'said']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #5\n",
      "['match', 'club', 'egypt', 'group', 'rohr', '2019', 'time', 'ldquo', 'world', 'game', 'rdquo', 'nations', 'players', 'africa', 'nigeria', 'team', 'rsquo', 'super', 'cup', 'eagles']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #6\n",
      "['parties', 'nigeria', 'buhari', 'pdp', 'people', 'political', 'presidential', 'court', 'state', 'inec', 'electoral', 'commission', 'party', 'president', 'elections', 'rsquo', 'rdquo', 'ldquo', 'said', 'election']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #7\n",
      "['2019', 'stock', 'banks', 'years', 'report', '2018', 'said', 'shares', 'company', 'year', 'cbn', 'mtn', 'market', 'according', 'exchange', 'billion', 'percent', 'million', 'nigeria', 'bank']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #8\n",
      "['world', 'child', 'new', 'singer', 'instagram', 'love', 'don', 'man', 'know', 'years', 'time', 'life', 'people', 'just', 'like', 'said', 'lsquo', 'rdquo', 'ldquo', 'rsquo']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #9\n",
      "['minute', 'manchester', 'city', 'second', 'half', 'minutes', 'win', 'premier', 'arsenal', 'champions', 'united', 'team', 'game', 'club', 'season', 'goals', 'goal', 'chelsea', 'rsquo', 'league']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the the TOP 20 words of the all Topics \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the sparse data on the fitted LDA object\n",
    "\n",
    "\n",
    "\n",
    "# Create a new column called 'Topic_lda' and save the Topic id's in it\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>articles</th>\n",
       "      <th>Topic_lda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What does it mean to be successful? Perhaps, o...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Much has been made of Africa&amp;rsquo;s unfavorab...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A few days after a Damaris Wambui Kamau and he...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\\n\\n\\n\\nJust a few hours after their release o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>IPOA is investigating the murder of four peopl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           articles  Topic_lda\n",
       "0   1  What does it mean to be successful? Perhaps, o...          3\n",
       "1   2  Much has been made of Africa&rsquo;s unfavorab...          4\n",
       "2   3  A few days after a Damaris Wambui Kamau and he...          0\n",
       "3   4  \\n\\n\\n\\nJust a few hours after their release o...          0\n",
       "4   5  IPOA is investigating the murder of four peopl...          0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the dataframe now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label dictionary for each topic, kinda like mine,\n",
    "#please go through the words in each topic to figure out a fitting \n",
    "#label for that topic and create a dictionary mapping each topic id \n",
    "#to its corresponding label (which is at your discretion)\n",
    "\n",
    "label_dict = {\n",
    "    0:'security',\n",
    "    1:'economy',\n",
    "    2:'economy',\n",
    "    3:'election',\n",
    "    4:'economy',\n",
    "    5:'football',\n",
    "    6:'election',\n",
    "    7:'stock',\n",
    "    8:'social',\n",
    "    9:'football'\n",
    "}\n",
    "\n",
    "# there seem to be just 6 unique labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>articles</th>\n",
       "      <th>Topic_lda</th>\n",
       "      <th>lda_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What does it mean to be successful? Perhaps, o...</td>\n",
       "      <td>3</td>\n",
       "      <td>election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Much has been made of Africa&amp;rsquo;s unfavorab...</td>\n",
       "      <td>4</td>\n",
       "      <td>economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A few days after a Damaris Wambui Kamau and he...</td>\n",
       "      <td>0</td>\n",
       "      <td>security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\\n\\n\\n\\nJust a few hours after their release o...</td>\n",
       "      <td>0</td>\n",
       "      <td>security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>IPOA is investigating the murder of four peopl...</td>\n",
       "      <td>0</td>\n",
       "      <td>security</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           articles  Topic_lda lda_labels\n",
       "0   1  What does it mean to be successful? Perhaps, o...          3   election\n",
       "1   2  Much has been made of Africa&rsquo;s unfavorab...          4    economy\n",
       "2   3  A few days after a Damaris Wambui Kamau and he...          0   security\n",
       "3   4  \\n\\n\\n\\nJust a few hours after their release o...          0   security\n",
       "4   5  IPOA is investigating the murder of four peopl...          0   security"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column called 'lda_labels' based on the map created above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for NMF\n",
    "Task: Use TF-IDF Vectorization to create a vectorized document term matrix. Use a max_df=0.9 and min_df=2 parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages i.e tfidfvectorizer, NMF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1001x10339 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 109044 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and transform the tfidfvectorizer on the articles using the params giving above\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "  n_components=10, random_state=10, shuffle=False, solver='cd', tol=0.0001,\n",
       "  verbose=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit an NMF instance to the sparse matrix from the tfidfvectorizer\n",
    "# Extracting 10 topics with a random state of 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 15 WORDS FOR TOPIC #0\n",
      "['national', 'administration', 'governors', 'federal', 'herdsmen', 'army', 'north', 'military', 'nigerians', 'people', 'rdquo', 'nigeria', 'security', 'said', 'buhari', 'state', 'country', 'ldquo', 'government', 'president']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #1\n",
      "['obi', 'match', 'burundi', 'injury', 'ighalo', 'coach', 'group', 'gernot', 'afcon', 'nigeria', 'egypt', 'mikel', 'nations', 'players', 'team', 'africa', 'rohr', 'cup', 'super', 'eagles']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #2\n",
      "['official', 'long', 'just', 'singer', 'man', 'songs', 'people', 'really', 'new', 'want', 'time', 'like', 'feel', 'world', 'don', 've', 'music', 'hellip', 'lsquo', 'rsquo']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #3\n",
      "['oil', 'plc', 'board', 'investors', 'million', 'said', 'percent', 'securities', 'billion', 'nigeria', 'nse', 'stock', 'commission', 'sec', 'shares', 'listing', 'exchange', 'market', 'mtn', 'company']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #4\n",
      "['goals', 'window', 'appearances', 'old', 'deal', 'city', 'summer', 'international', 'turkish', 'fenerbahce', 'player', 'premier', 'year', 'transfer', 'loan', 'moses', 'league', 'club', 'season', 'chelsea']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #5\n",
      "['ldquo', 'abubakar', 'votes', 'democratic', 'national', 'said', 'state', 'president', 'candidate', 'commission', 'apc', 'buhari', 'atiku', 'presidential', 'electoral', 'pdp', 'elections', 'party', 'inec', 'election']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #6\n",
      "['score', 'arsenal', 'scored', 'liverpool', 'united', 'falcons', 'team', 'second', 'half', 'final', 'minutes', 'goals', 'match', 'barcelona', 'champions', 'win', 'minute', 'league', 'goal', 'game']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #7\n",
      "['time', 'people', 'old', 'like', 'love', 'god', 'just', 'know', 'wrote', 'police', 'instagram', 'actor', 'children', 'life', 'ndash', 'family', 'rsquo', 'said', 'rdquo', 'ldquo']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #8\n",
      "['growth', 'merger', 'loans', 'development', 'nexim', 'sector', 'central', 'billion', 'customers', 'said', 'banking', 'plc', 'emefiele', 'nigeria', 'access', 'diamond', 'financial', 'banks', 'cbn', 'bank']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #9\n",
      "['known', 'boys', 'fashola', 'nigerian', 'davido', 'musician', 'ldquo', 'guilty', 'money', 'jail', 'justice', 'bail', 'crimes', 'singer', 'fraud', 'court', 'yahoo', 'naira', 'efcc', 'marley']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the the TOP 20 words of the all Topics \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>articles</th>\n",
       "      <th>Topic_lda</th>\n",
       "      <th>lda_labels</th>\n",
       "      <th>Topic_nmf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What does it mean to be successful? Perhaps, o...</td>\n",
       "      <td>3</td>\n",
       "      <td>election</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Much has been made of Africa&amp;rsquo;s unfavorab...</td>\n",
       "      <td>4</td>\n",
       "      <td>economy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A few days after a Damaris Wambui Kamau and he...</td>\n",
       "      <td>0</td>\n",
       "      <td>security</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\\n\\n\\n\\nJust a few hours after their release o...</td>\n",
       "      <td>0</td>\n",
       "      <td>security</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>IPOA is investigating the murder of four peopl...</td>\n",
       "      <td>0</td>\n",
       "      <td>security</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           articles  Topic_lda  \\\n",
       "0   1  What does it mean to be successful? Perhaps, o...          3   \n",
       "1   2  Much has been made of Africa&rsquo;s unfavorab...          4   \n",
       "2   3  A few days after a Damaris Wambui Kamau and he...          0   \n",
       "3   4  \\n\\n\\n\\nJust a few hours after their release o...          0   \n",
       "4   5  IPOA is investigating the murder of four peopl...          0   \n",
       "\n",
       "  lda_labels  Topic_nmf  \n",
       "0   election          2  \n",
       "1    economy          3  \n",
       "2   security          7  \n",
       "3   security          7  \n",
       "4   security          7  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforn the data on the fitted NMF instance\n",
    "\n",
    "\n",
    "# Create a new column called Topic_nmf and save the Topic id's in it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the same set of labels now rearrange them to suit the topics \n",
    "#i.e if topic 7 for lda was labeled election, but now topic 7 looks \n",
    "#to be social, then modify the labels_dict accordingly to suit NMF\n",
    "\n",
    "label_dict = {\n",
    "    0:'security',\n",
    "    1:'football',\n",
    "    2:'social',\n",
    "    3:'stock',\n",
    "    4:'football',\n",
    "    5:'election',\n",
    "    6:'football',\n",
    "    7:'social',\n",
    "    8:'economy',\n",
    "    9:'social'\n",
    "}\n",
    "# maintaining the six unique labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>articles</th>\n",
       "      <th>Topic_lda</th>\n",
       "      <th>lda_labels</th>\n",
       "      <th>Topic_nmf</th>\n",
       "      <th>nmf_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What does it mean to be successful? Perhaps, o...</td>\n",
       "      <td>3</td>\n",
       "      <td>election</td>\n",
       "      <td>2</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Much has been made of Africa&amp;rsquo;s unfavorab...</td>\n",
       "      <td>4</td>\n",
       "      <td>economy</td>\n",
       "      <td>3</td>\n",
       "      <td>stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A few days after a Damaris Wambui Kamau and he...</td>\n",
       "      <td>0</td>\n",
       "      <td>security</td>\n",
       "      <td>7</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\\n\\n\\n\\nJust a few hours after their release o...</td>\n",
       "      <td>0</td>\n",
       "      <td>security</td>\n",
       "      <td>7</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>IPOA is investigating the murder of four peopl...</td>\n",
       "      <td>0</td>\n",
       "      <td>security</td>\n",
       "      <td>7</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           articles  Topic_lda  \\\n",
       "0   1  What does it mean to be successful? Perhaps, o...          3   \n",
       "1   2  Much has been made of Africa&rsquo;s unfavorab...          4   \n",
       "2   3  A few days after a Damaris Wambui Kamau and he...          0   \n",
       "3   4  \\n\\n\\n\\nJust a few hours after their release o...          0   \n",
       "4   5  IPOA is investigating the murder of four peopl...          0   \n",
       "\n",
       "  lda_labels  Topic_nmf nmf_labels  \n",
       "0   election          2     social  \n",
       "1    economy          3      stock  \n",
       "2   security          7     social  \n",
       "3   security          7     social  \n",
       "4   security          7     social  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column called lda_labels based on the map created above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650\n"
     ]
    }
   ],
   "source": [
    "# How many of the articles share the same label \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.94%\n"
     ]
    }
   ],
   "source": [
    "# What % of our articles were labelled with the same label by both topic models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional Challenge: Text Generation with Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the oliver-twist-0-9.txt text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import spacy\n",
    "nlp = spacy.load('en',disable=['parser', 'tagger','ner'])\n",
    "# Increase the allowable max lentgh\n",
    "nlp.max_length = 1198623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this function to seperate punctuations\n",
    "def separate_punc(doc_text):\n",
    "    \n",
    "    return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']\n",
    "tokens = separate_punc(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Sequences of Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize into sequences of tokens\n",
    "train_len = 25+1 # 50 training words , then one target word\n",
    "\n",
    "# Empty list of sequences\n",
    "text_sequences = []\n",
    "\n",
    "for i in range(train_len, len(tokens)):\n",
    "    \n",
    "    # Grab train_len# amount of characters\n",
    "    seq = tokens[i-train_len:i]\n",
    "    \n",
    "    # Add to list of sequences\n",
    "    text_sequences.append(seq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(tokenizer.word_counts)\n",
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an LSTM based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your own custom model\n",
    "def create_model(vocabulary_size, seq_len):\n",
    "    \n",
    "    #CODE IN HERE\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Test Split\n",
    "X = sequences[:,:-1]\n",
    "y = sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocabulary_size+1)\n",
    "seq_len = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump,load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ikezogwo/anaconda3/envs/nlp_course/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 25, 25)            109300    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 25, 150)           105600    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 150)               180600    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4372)              660172    \n",
      "=================================================================\n",
      "Total params: 1,078,322\n",
      "Trainable params: 1,078,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/ikezogwo/anaconda3/envs/nlp_course/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "30742/30742 [==============================] - 172s 6ms/step - loss: 6.6432 - acc: 0.0579\n",
      "Epoch 2/30\n",
      "30742/30742 [==============================] - 167s 5ms/step - loss: 6.2309 - acc: 0.0620\n",
      "Epoch 3/30\n",
      "30742/30742 [==============================] - 155s 5ms/step - loss: 6.0896 - acc: 0.0631\n",
      "Epoch 4/30\n",
      "30742/30742 [==============================] - 160s 5ms/step - loss: 5.9151 - acc: 0.0763\n",
      "Epoch 5/30\n",
      "30742/30742 [==============================] - 166s 5ms/step - loss: 5.8008 - acc: 0.0794\n",
      "Epoch 6/30\n",
      "30742/30742 [==============================] - 163s 5ms/step - loss: 5.7106 - acc: 0.0829\n",
      "Epoch 7/30\n",
      "30742/30742 [==============================] - 171s 6ms/step - loss: 5.6248 - acc: 0.0872\n",
      "Epoch 8/30\n",
      "30742/30742 [==============================] - 162s 5ms/step - loss: 5.5401 - acc: 0.0930\n",
      "Epoch 9/30\n",
      "30742/30742 [==============================] - 174s 6ms/step - loss: 5.4410 - acc: 0.1031\n",
      "Epoch 10/30\n",
      "30742/30742 [==============================] - 165s 5ms/step - loss: 5.3254 - acc: 0.1158\n",
      "Epoch 11/30\n",
      "30742/30742 [==============================] - 142s 5ms/step - loss: 5.2261 - acc: 0.1239\n",
      "Epoch 12/30\n",
      "30742/30742 [==============================] - 138s 4ms/step - loss: 5.1366 - acc: 0.1317\n",
      "Epoch 13/30\n",
      "30742/30742 [==============================] - 136s 4ms/step - loss: 5.0523 - acc: 0.1366\n",
      "Epoch 14/30\n",
      "30742/30742 [==============================] - 137s 4ms/step - loss: 4.9707 - acc: 0.1425\n",
      "Epoch 15/30\n",
      "30742/30742 [==============================] - 137s 4ms/step - loss: 4.8963 - acc: 0.1457\n",
      "Epoch 16/30\n",
      "30742/30742 [==============================] - 138s 4ms/step - loss: 4.8162 - acc: 0.1506\n",
      "Epoch 17/30\n",
      "30742/30742 [==============================] - 141s 5ms/step - loss: 4.7395 - acc: 0.1543\n",
      "Epoch 18/30\n",
      "30742/30742 [==============================] - 136s 4ms/step - loss: 4.6667 - acc: 0.1560\n",
      "Epoch 19/30\n",
      "30742/30742 [==============================] - 142s 5ms/step - loss: 4.5949 - acc: 0.1604\n",
      "Epoch 20/30\n",
      "30742/30742 [==============================] - 165s 5ms/step - loss: 4.5240 - acc: 0.1636\n",
      "Epoch 21/30\n",
      "30742/30742 [==============================] - 142s 5ms/step - loss: 4.4554 - acc: 0.1658\n",
      "Epoch 22/30\n",
      "30742/30742 [==============================] - 131s 4ms/step - loss: 4.3911 - acc: 0.1723\n",
      "Epoch 23/30\n",
      "30742/30742 [==============================] - 132s 4ms/step - loss: 4.3312 - acc: 0.1735\n",
      "Epoch 24/30\n",
      "30742/30742 [==============================] - 132s 4ms/step - loss: 4.2654 - acc: 0.1771\n",
      "Epoch 25/30\n",
      "30742/30742 [==============================] - 171s 6ms/step - loss: 4.2034 - acc: 0.1806\n",
      "Epoch 26/30\n",
      "30742/30742 [==============================] - 137s 4ms/step - loss: 4.1447 - acc: 0.1843\n",
      "Epoch 27/30\n",
      "30742/30742 [==============================] - 138s 4ms/step - loss: 4.1015 - acc: 0.1856\n",
      "Epoch 28/30\n",
      "30742/30742 [==============================] - 146s 5ms/step - loss: 4.0457 - acc: 0.1880\n",
      "Epoch 29/30\n",
      "30742/30742 [==============================] - 141s 5ms/step - loss: 3.9925 - acc: 0.1925\n",
      "Epoch 30/30\n",
      "30742/30742 [==============================] - 140s 5ms/step - loss: 3.9388 - acc: 0.1969\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dump' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-a18a128ba58d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epochBIG.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# save the tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epochBIG'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dump' is not defined"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = create_model(vocabulary_size+1, seq_len)\n",
    "# fit model\n",
    "model.fit(X, y, batch_size=128, epochs=30,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to file\n",
    "model.save('epoch30.h5')\n",
    "# save the tokenizer\n",
    "dump(tokenizer, open('epoch30', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating New Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "    '''\n",
    "    INPUTS:\n",
    "    model : model that was trained on text data\n",
    "    tokenizer : tokenizer that was fit on text data\n",
    "    seq_len : length of training sequence\n",
    "    seed_text : raw string text to serve as the seed\n",
    "    num_gen_words : number of words to be generated by model\n",
    "    '''\n",
    "    \n",
    "    # Final Output\n",
    "    output_text = []\n",
    "    \n",
    "    # Intial Seed Sequence\n",
    "    input_text = seed_text\n",
    "    \n",
    "    # Create num_gen_words\n",
    "    for i in range(num_gen_words):\n",
    "        \n",
    "        # Take the input text string and encode it to a sequence\n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        \n",
    "        # Pad sequences to our trained rate (50 words in the video)\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "        \n",
    "        # Predict Class Probabilities for each word\n",
    "        pred_word_ind = model.predict_classes(pad_encoded, verbose=0)[0]\n",
    "        \n",
    "        # Grab word\n",
    "        pred_word = tokenizer.index_word[pred_word_ind] \n",
    "        \n",
    "        # Update the sequence of input text (shifting one over with the new word)\n",
    "        input_text += ' ' + pred_word\n",
    "        \n",
    "        output_text.append(pred_word)\n",
    "        \n",
    "    # Make it look like a sentence.\n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab a random seed sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(102)\n",
    "random_pick = random.randint(0,len(text_sequences))\n",
    "random_seed_text = text_sequences[random_pick]\n",
    "seed_text = ' '.join(random_seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and a great deal of the workhouse and a week and was beyond the street and a great number of bread and a slice of bread and a slice of'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
